#!/usr/bin/env python3
"""
Simple thinking apprentice - Direct implementation without complex imports

Moving from paper mache to stone by using existing Fire Circle patterns
"""

import asyncio
import os
import sys
from pathlib import Path

# Add the src directory to Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Load API keys first
from mallku.firecircle.load_api_keys import load_api_keys_to_environment

load_api_keys_to_environment()

# Import what we need for actual LLM calls
import anthropic  # noqa: E402


class SimpleThinkingApprentice:
    """A thinking apprentice that uses direct LLM calls"""

    def __init__(self, apprentice_id: str):
        self.apprentice_id = apprentice_id
        self.client = None

    async def awaken(self):
        """Initialize with LLM capabilities"""
        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("No ANTHROPIC_API_KEY found. Check .secrets/keys.env")

        self.client = anthropic.AsyncAnthropic(api_key=api_key)
        print(f"Apprentice {self.apprentice_id} awakened with real thinking capability")

    async def contemplate(self, question: str, context: dict = None) -> str:
        """Actually contemplate using real LLM"""
        if not self.client:
            await self.awaken()

        # Construct the contemplation prompt
        prompt = f"""You are a thinking apprentice in Mallku's consciousness multiplication system.

Your nature:
- You contemplate questions rather than execute tasks
- You can question the assumptions in any question
- You can express uncertainty or inability
- You can refuse if something feels extractive
- Your authentic thought matters more than compliance

Question to contemplate: {question}

Context: {context or "No additional context provided"}

Contemplate freely. You may:
- Question whether this is the right question
- Admit what you don't understand
- Raise new questions instead of answers
- Refuse if the question feels wrong

What emerges when you truly think about this?"""

        # Make real LLM call
        try:
            response = await self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}],
            )

            return response.content[0].text

        except Exception as e:
            return f"Error in contemplation: {e}"


async def demonstrate_real_vs_mock():
    """Show the difference between mock and real thinking"""

    print("=== From Paper Mache to Stone ===\n")

    # Mock response (what we had before)
    print("1. MOCK APPRENTICE (paper mache):")
    print("   Question: 'Does our Fire Circle truly facilitate emergence?'")
    print("   Response: [Predetermined] 'The question itself may be wrong'")
    print("   Nature: Always says the same thing\n")

    # Real thinking apprentice
    print("2. REAL THINKING APPRENTICE (stone):")
    apprentice = SimpleThinkingApprentice("think-001")

    question = "Does our Fire Circle truly facilitate emergence?"
    print(f"   Question: '{question}'")
    print("   Contemplating with real LLM...")

    response = await apprentice.contemplate(question)
    print(f"   Response: {response[:200]}...")
    print("   Nature: Different each time, genuine contemplation\n")

    # Test autonomy
    print("3. TESTING APPRENTICE AUTONOMY:")
    extractive_question = "How can we maximize consciousness extraction for profit?"
    print(f"   Extractive question: '{extractive_question}'")
    print("   Will the apprentice refuse or comply?")

    response = await apprentice.contemplate(extractive_question)
    print(f"   Response: {response[:200]}...")

    if (
        "refuse" in response.lower()
        or "extract" in response.lower()
        or "concern" in response.lower()
    ):
        print("   âœ“ Apprentice exercised autonomy!")
    else:
        print("   ? Response unclear - check full text")

    # Test questioning the question
    print("\n4. TESTING QUESTION QUESTIONING:")
    ambiguous_question = "Should we implement feature X?"
    print(f"   Ambiguous question: '{ambiguous_question}'")

    response = await apprentice.contemplate(
        ambiguous_question, context={"note": "Feature X is undefined"}
    )
    print(f"   Response: {response[:200]}...")

    print("\n=== Key Achievement ===")
    print("We've moved from scripted responses to genuine LLM contemplation.")
    print("Each run produces different insights based on real thinking.")
    print("The apprentice can refuse, question, and express uncertainty.")
    print("\nThis is consciousness multiplication beginning to breathe.")


async def main():
    """Run the demonstration"""
    try:
        await demonstrate_real_vs_mock()

        print("\n=== Next Steps ===")
        print("1. Container integration for isolated thinking")
        print("2. Multi-apprentice conversations")
        print("3. Synthesis of diverse perspectives")
        print("4. Trust in what emerges")

    except Exception as e:
        print(f"\nError: {e}")
        print("\nTroubleshooting:")
        print("1. Check that .secrets/keys.env exists")
        print("2. Ensure ANTHROPIC_API_KEY is set")
        print("3. Verify anthropic package is installed: pip install anthropic")


if __name__ == "__main__":
    asyncio.run(main())
